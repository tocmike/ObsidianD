---
source: https://x.7ds.me/archives/81523
---
![[./_resources/»_日用而不知的难题.resources/embedded.svg]]
日用而不知的难题
00:00 / 00:00
An audio error has occurred.

## 日用而不知的难题



2021-02-24
![[./_resources/»_日用而不知的难题.resources/202102231438066158453954.jpeg]]
现在 AI 是越来越厉害了……而要不是跟 AI 比，人都不知道自己原来有多厉害。先请你看一张照片 ——
![[./_resources/»_日用而不知的难题.resources/202102232012586712905773.jpg]]
照片中是十几个穿着西装的男子，其中一个是美国前总统奥巴马。有个人在体重秤上站着称体重，其他人都微笑地看着他。
你用不了一秒钟就能理解那些人为什么笑。称体重的那位老兄不知道，站在他身后的奥巴马正在用脚压那个体重秤 —— 这样会让他称到一个更重的重量。你能看出来所有人的笑都是友善的。你设想，可能大家觉得这个玩笑很好玩，也可能是大家觉得奥巴马以总统之尊开这个玩笑、这件事儿更有意思。
现在我们的问题是，**AI，得发展到什么程度，才能看出来这张照片的“有意思”？**
计算机视觉专家安德烈·卡帕蒂（Andrej Karpathy）在他的一篇博客文章 \[1\] 中使用了这个图。==他的结论是我们距离那一天非常、非常遥远==。这张图只是一组很短的二维颜色数列而已，可是它代表的是人类知识的冰山一角。
为了看懂这张照片，你得知道体重秤是干什么用的，你得知道施加压力能增大体重秤的读数，你得知道为什么这个可以笑，你得知道奥巴马是谁，等等等。一个还没上小学的人类儿童都能看明白这张照片，而她的知识就已经太多了，多到计算机科学家不知道怎么才能让 AI 掌握的程度。
这种我们都有，而 AI 都还没有的，==很多是「隐性知识（tacit knowledge）」，也叫做「常识」。==
＊
深度学习也好、强化学习也罢，AI 的知识都是基于经验的，都是来自数据。我们讲《为什么》的时候说过，朱迪亚·珀尔有句名言叫「数据是深度愚蠢的」\[2\]。我们经常赞叹现在 AI 有多厉害，==但是现在 AI 的武功都有很简单的命门。==
比如说图像识别。我们知道现在基于卷积网络和深度学习的图像识别已经非常强大了 \[3\]。现在有些智能监控摄像头，会自动识别人脸，而为了识别人脸，它必须知道图像中哪个东西是“人”，对吧？2019 年，比利时鲁汶大学的几个人发明了一种彩色图形，可以骗过 AI 识别。你只要把这个图形打印到一张纸上 —— 不用太大，差不多是一张 A4 纸的大小 —— 然后把这张纸挂在身上 —— 不用蒙住脸，挂在肚子上就行 —— AI 就不会把你当做“人” \[4\]。
![[./_resources/»_日用而不知的难题.resources/202102232013596129065668.gif]]
![[./_resources/»_日用而不知的难题.resources/202102232014278123385287.gif]]
![[./_resources/»_日用而不知的难题.resources/202102232015018657793122.gif]]
这可不是个例。事实上比利时这项研究是现在很流行的一种“运动”的一部分，叫做「对抗攻击（adversarial attack）」：专门寻找 AI 图像识别的命门，用一招破解它。
侯世达的学生、波特兰州立大学计算机科学家梅拉妮·米歇尔（Melanie Mitchell）2019 年出了本书叫《AI 3.0》（得到有湛庐文化出的中文版，英文书名是 _Artificial Intelligence: A Guide for Thinking Humans_）\[5\]，这本书一定程度上代表了学界对 AI 的能力的当前科学理解。米歇尔在书中列举了好几个对抗攻击的例子，你体会一下 ——
下面这两张图，左边是原始照片，AI 正确地识别到是一辆校车。右边这张图，研究者做了一些调整，你用肉眼恐怕难以看出来跟左边有什么区别，可是 AI 却把它识别成了“鸵鸟”。
![[./_resources/»_日用而不知的难题.resources/202102232015339134123272.png]]
下面这几张图，在我们眼中只是一些雪花点，可是 AI 却把它们识别成了“欧洲知更鸟”“猎豹”“蜈蚣”和“雄孔雀”。
![[./_resources/»_日用而不知的难题.resources/202102232016069117826285.png]]
一个男性研究者戴上一副特殊的眼镜，AI 就把他识别成了一个著名女演员。
![[./_resources/»_日用而不知的难题.resources/202102232016393621245194.png]]
这些都是怎么回事儿呢？可能是因为 AI 的图像识别都是从细节入手的。AI 并不是像人眼这样看图先看个大概轮廓，它不知道物体占图像面积的比例是多少，它必须注意图中哪怕是很小的物体，否则如果图中有只小虫子它就发现不了。而人眼忽略掉的一些细节，在它眼中却是至关重要的特征结构。
==这里面的深层原因是 AI 不知道各个细节元素之间的逻辑关系==。
＊
==“经验”可以有各种角度。如果只是观察而不懂得原理，你可能会总结一个错误的经验。==米歇尔组里有个研究生，自己用现成的图形库训练了一个能判断“这张照片中有没有动物”的深度神经网络。这个网络的准确度非常高，但是研究生仔细研究之后，发现一个大问题。
==那个网络是通过“照片中有没有虚化的背景”来判断其中有没有动物的==。如同下面这两张图 ——
![[./_resources/»_日用而不知的难题.resources/202102232017247142448397.png]]
（A）中有动物，摄影师拍摄的时候聚焦在动物身上，所以背景是虚化模糊的；（B）中没有动物，就是一张自然景观照，所以没有虚化的部分。==这只是摄影师的拍摄习惯而已！而那个深度神经网络恰恰把这个，当做了判断有没有动物的标准。它并没有真的学会识别动物。==
==所有 AI 识别系统都有命门==，你绕不过去。归根结底，经验是由训练素材决定的。有研究发现只要换做机器人去房间里各个地方随机地拍照片 —— 而不像人类摄影师那样选择合适的角度拍 —— AI 就很难识别这些照片中的东西：因为它们没见过这么拍照片的。
==这就是统计经验不可避免的命门==。AI 非常不善于处理不常出现的情况，它们带有各种偏见。如果一个男人站在厨房里，他就很有可能被识别为女人 —— 毕竟对大数据来说，女人在厨房出现的可能性更大。快下雪了，市政当局在公路上预先洒下了盐，形成“盐线”，特斯拉汽车的自动驾驶系统没见过这样的线，结果就发生了功能紊乱。
![[./_resources/»_日用而不知的难题.resources/202102232018220653678051.png]]
==其实我也是第一次看到盐线。但是如果我开车遇到盐线，我就能看出来它们和正常交通标志线的区别，我很可能还可以猜出来它们是干什么用的。==
==因为我有常识。==
＊
米歇尔说，当今学界基本上达成了一个共识，也是现阶段的研究热点，就是让 AI 学习人类的常识。Cycorp 公司有个项目叫 Cyc，就是一个专门针对 AI 的人类常识系统。Cyc 中的一些常识是下面这样的 ——
\*一个实体不能同时身处多个地点。
\*一个对象每过一年会老一岁。
\*每个人都有一个女性人类母亲。
然后 Cyc 还会基于这些常识做逻辑推理。比如如果你告诉它现在你在北京，它就知道你不在哈尔滨。可是这里面有个大问题。
==像这样的常识，都是我们都知道 —— 可是我们\*不知道\*我们知道 —— 的知识==。你知道你会多少条常识吗？你能把它们一条条地都写出来吗？你不知道。Cyc 系统中像这样的常识已经有了 1500 万条 —— 我都不知道那些研究者是怎么列举出来这么多的 —— 而据 Cycorp 公司判断，这些还只是最终所需要的常识总数的 5%。
你能想象吗？你有那么多条知识。这还不算有很多知识是你能随时生成、而 AI 却很难看出来的。米歇尔列举了俄罗斯计算机科学家米哈伊尔·邦加德（Mikhail Bongard）发明的一类问题，叫「邦加德问题（Bongard problems）」，你体会一下。下面这些问题中，每组左边的六张图跟右边的六张图有个区别，你能说出来是什么区别吗？
![[./_resources/»_日用而不知的难题.resources/202102232019227116599876.png]]
对你来说这一点都不难。比如第2题，左边的图形都比较大，右边的都比较小；第3题，左边都是空心的，右边都是实心的……你一定能做出来下面这道题：测试样本中那个图形，应该归类于类别 1，还是类别 2 呢？
![[./_resources/»_日用而不知的难题.resources/202102232019562159415196.png]]
答案当然是类别 1，因为图中两个物体的形状和大小都一样。这些题目中每道题的规律都不一样，可是我们都能轻松看出来。我们做每道题只用了六个样本！有人用两万个样本训练一个卷积网络做上边这道题，结果 AI 的表现只比随机猜测好一点点。
如果你感兴趣的话还可以尝试一下下面这几道更难一点的邦加德问题，AI 绝对无能为力 ——
![[./_resources/»_日用而不知的难题.resources/202102232020534139648052.png]]
对 AI 来说，这些题可比下围棋难多了。你是怎么找到那些关键区别的？计算机科学家肯定说不清楚。==我们人类有迅速感知新概念的能力，这个能力的背后可能是**「类比」**==。但这句话说了等于没说，因为我们很难说清「类比」到底是怎样一个过程。不论如何，这是我们目前为止绝对的特长。
＊
经过跟 AI 的对比，我们似乎也加深了对自己的理解。原来我们知道这么多说不清道不明的知识。其实哪怕你抛开 AI 不论，单纯研究人类的这些隐性知识也很有意思。
有些常识，你意识不到也就意识不到，但是一旦意识到，会发现其中有个很妙的逻辑。我给你举个例子。
有一个婴儿和一个机器人都快要掉下悬崖了，你正好在旁边，你会救谁呢？肯定是救婴儿，毕竟那是一个活生生的人，而机器人只是机器。可为什么人就比机器该被救呢？
有一位县长，公然用拳头猛打一个五岁小女孩的脸，你肯定会谴责这个县长。可是如果反过来，如果是这个小女孩用拳头打这位县长，你肯定觉得无所谓。那这又是为什么呢？
你不一定仔细想过为什么，可是你的直觉已经告诉你该怎么判断了。==那人类的道德判断，有什么客观标准吗？==
有本书叫《人心的本质》（2020，得到电子书有）作者是两位加拿大心理学家，丹尼尔·韦格纳和库尔特·格雷。这本书中对此提出了一个“统一理论”。==这本书说人有两种心智能力。一种叫「感受性（experience）」，意思是你能感觉到痛苦。一种叫「能动性（agency）」，意思是你的行动力。这个理论说，==
**道德程度的高低 ＝ 主体的能动性 ＋ 受体的感受性**
什么意思呢？小婴儿是人，他有充分的感受性，而机器人没有，所以我们应该救小婴儿。县长大人打人的能动性很强，他挨小女孩打的感受性很弱，而小女孩正好相反，所以小女孩打县长可以，县长打小女孩不行。
就这么简单。两位作者据此推导出一系列有意思的结论。
所以你看，这就是人类常识的有意思之处：我们日用而不知。你遇到各种情况都知道该怎么办，可是如果没遇到那些情况，你说不清你知道多少个“怎么办”。你从来没刻意学习过，甚至从来都没想过你知道那些，但你就是知道。这是人工智能远远不如人的地方，也可能是目前所知人类最重要的特长。这些常识有可能像「能动性」和「感受性」那样进一步简化，但也有可能是语言所无法穷尽的。
这个局面很奇妙。生而为人，你都不知道你有多厉害。
划重点
你遇到各种情况都知道该怎么办，可是如果没遇到那些情况，你说不清你知道多少个“怎么办”。你从来没刻意学习过，甚至从来都没想过你知道那些，但你就是知道。这是人工智能远远不如人的地方，也可能是目前所知人类最重要的特长。
**注释**
\[1\] Andrej Karpathy, The state of Computer Vision and AI: we are really, really far away. Oct 22, 2012, http://karpathy.github.io/2012/10/22/state-of-computer-vision/
\[2\] 精英日课第二季，《为什么》1：洞见因果的三种思维
\[3\] 精英日课第三季，学习一个“深度学习”算法（1）（2）（3）
\[4\] 智东西，《神奇贴纸骗过AI！人类被“隐形”，智能监控的危机来了？》https://zhidx.com/p/146179.html
\[5\] 这个 Melanie Mitchell 2009 年的一本书叫 Complexity: A Guided Tour，我仔细读过，写得非常好，推荐。
![[./_resources/»_日用而不知的难题.resources/202102232022266123578324.jpg]]

默认最新只看作者回复

海绵10小时前

TechTalks 的创始人Ben Dickson，曾经针对人工智能系统如何免遭对抗攻击发表过言论。 他说在生物鉴别认证和医学成像等关键应用中使用的机器学习算法必须经过审核，以确保它们能可靠地防御对抗攻击，而对抗漏洞是一颗定时炸弹，只有系统化的应对措施才能化解它。 他也在文中为我们提供了愿景，如下： 2021年1月，由微软、IBM、英伟达、MITRE 以及其他安全和人工智能公司的研究人员发布的 Adversarial ML Threat Matrix，为安全研究人员提供了一个框架，用于寻找包含机器学习组件的软件生态系统中存在的薄弱点和潜在的对抗漏洞。Adversarial ML Threat Matrix 遵循 ATT&CK 框架，这是安全研究人员中已知且可信的格式。 另一个有用的项目是 IBM 的 Adversarial Robustness Toolbox，这是一个开源的 Python 库，它提供了评估机器学习模型的对抗性漏洞的工具，并帮助开发人员加强他们的人工智能系统。 随着人工智能应用范围的不断扩大，我们也发现了AI的命门，AI不具备人类拥有的诸多常识，所以，我们还是高估了人工智能的进步，而忽略了人类自身智能的复杂性。 不可否认的是，“智能+”依然是未来发展主流，如何进一步修缮人工智能的对抗漏洞，也变得迫在眉睫了。

作者回复：

推荐！

时间移民10小时前

请问万老师，可不可以认为人脑比机器强太多，是因为人脑的运算能力一定比机器高很多个数量级才对？但是我们的经验是人脑很不擅长计算…人脑有可能是一台量子计算机吗？

作者回复：

不是的。是人脑的神经元连接比计算机复杂，而我们并不知道人脑的全部原理。不过计算机即将可以模拟整个人脑的硬件结构。

Bachmozani Tchaikofievendelssohn昨天

数据深度愚蠢，AI就是神经病。人类神经元wire together fire together.深度学习算法wire together fart together

作者回复：

哈哈哈哈

夏一哂9小时前

常识听着像是几十年前的专家系统，可以这样理解么？

作者回复：

是可以这样理解！特点是一条一条手动输入，优点是自动举一反三（如果可以的话）。。。

H永行5小时前

万老师介绍一下毅力号的着陆技术吗？气囊的问题是啥，怎么不用了？

作者回复：

气囊是没办法的办法，用气囊着陆得蹦跳几十次，蹦来蹦去容易把仪器搞坏，而且着陆地点不可控。现在都用反推火箭了。

常觉不住10小时前

用AI来识别图像，进而讲出图像中可能发生的故事，就必须提到斯坦佛大学华裔女教授李飞飞。李教授出生于北京，在成都长大，16岁移民美国，毕业于普林斯顿大学计算机系，并获有加州理工学院电机工程博士学位。毕业之后先后在伊利诺大学和普林斯顿大学任教，于2009年加入斯坦佛大学。在2010到2017年，李教授主持了一个大型图像计划 ILSVRC ，简称 ImageNet。 ImageNet收集了全世界来自于167个国家，超过一千四百万张的相片，用了将近五万人来标志相片中的情景。譬如说，相片中有车子、猫、天空、房子等等。目的就是要教 AI 如何学习和识别不同的对象。在经过一连串的机器学习和识别对象之后，李教授试图让AI 从图像中说故事。 2015年李教授在Ted有一个非常有名的演讲： “我们如何教计算机理解图像” （How we teach computers to understand pictures）［1］。有兴趣的同学可以去看一看。李教授在演讲中说ImageNet 计划的难度在于：（1）AI 会误判没有学习过的东西，譬如说AI 会将一个牙刷以为是一个棒球棒、将松鼠误以为是海狮、将雕像误以为是真人实体；（2）即使是学习过的对象，ImageNet的精确度还是个问题。 2018年以后， ImageNet  就没有新的发展。目前用图像说故事所遭遇到的两个最大瓶颈在于：(1）正如万老师在课堂中所说的，AI 缺乏人们的 “基本常识”;（2） AI 对图像识别的精确度一直无法有效提升。ImageNet的精确度能达到95%，但是想要从95% 再提升上去，是非常难的，从2017年以来就没有成功过。 近年来李教授的研究工作，扩展到 AI 和医疗保健领域。 参考［1］ https://www.youtube.com/watch?v=40riCqvRoMs

刘嘉9小时前

影响AI发展最大的限制，是人类对自己的了解程度。

Scenery4小时前

![[./_resources/»_日用而不知的难题.resources/1f518.png]]活在『语境』和特定『场景』中的人工智能，其价值在于构造一种独特的问题框架和反思视角，甚至可能是消解某些问题，但也可能是『创造』问题。我们与AI感觉就是共存关系，但依然不能『感同身受』。 ![[./_resources/»_日用而不知的难题.resources/1f518.png]]『你的习以为常却是AI的洞见』，反之亦然。AI能做的很多事情，不如说是以人工智能为名，回应着它所理解的日常生活的独特性。 ![[./_resources/»_日用而不知的难题.resources/1f518.png]]在需要强大算力，又繁琐重复的问题上，AI可以说是超越了人类。但要让AI像小孩子一样去感知外部世界并自由地应对环境是非常困难的。它不具备常识，人类相对AI是强大而不自知。一两岁的小孩子都能很好地处理环境信息，能平衡自己的身体以躲避危险，能灵活的感知行动和自适应，而且，运用这种能力时，小孩子是不需要什么逻辑推理和精心算计的。这是因为大量的感知行为能力是依赖基本常识、情感以及一定的自我意识的。而这些很难算法化的，要机器像人类那样具有自我意识，就是更加难以想象的事情了，这或许也是AI未来的发展的方向吧。

我叫张子鸣昨天

人啊人 今年年初，村干部们迎来福利，年终了，没有什么年终奖，一人发了一个手机。拍照高清、定位清晰、刷抖音流畅，大家玩得不亦乐乎。 一个星期后，正式通知来了，这是一个工作手机。以后做什么，用这个手机拍照片，里面设置了水印手机。一拍就清楚的知道你在哪里，经度纬度都出来了，还有时间也明明白白。我们干部说让他那句古话：“阎王要你三更死，无法留人到五更”。你已经被手机绑定了。 但是智能手机，它也不完全智能啊。他们去房屋确权，一拍照片，位置和上级的地图对不上。后来发现，你不能在门口拍，你得到顶楼拍，这样才会准确。解释是这个手机连的是上级的卫星定位，顶楼靠近卫星。村干部的腿力在长期爬楼中得到锻炼。 还有时间有时候也会出错，领导一看水印，时间不对，没及时完成。解释半天，都相信智能手机不会撒谎，肯定是人撒谎了。最后工程师一测，还真有问题。 我是绝对支持农村工作信息化，那样很便利。但是要考虑到干部实际情况以及配套措施，不能一刀切。照片是水印照片，手机是智能手机，但是人，他也是人嘛。

帮主jym88978634昨天

今天日课让我想到了该以何种态度看待AI。 1.如果是以一种竞争的态度，那我们大可同意其中的大部分观点。AI有命门，简单武功可破，常识还不如一个五六岁的小孩。 但从这个视角看过去，显然映照出了一个不成熟的我们，一个幸灾乐祸一脸坏笑的我们。 2.如果我们换成鼓励伙伴的立场，事情就有了变化。把AI看成是我们刚刚领养的一个伙伴，猫狗一样的宠物，还需要我们喂养。那在某些场合，我们可以很轻易地就告诉它这是一张有意思的照片，这张照片里有好看的动物。又比如在另外一些场合，它会告诉我们黑子落在这里，有85.43%的胜率，从来没有人类棋手这样下过的一步。 3.如果再换成一个镜像的角度，事情就有了更加深刻的意义。它会让我们成为更好的自己。从来没有人像它那样冷静、全面、客观地了解过我，哪些工作适合我做，哪些事情对于我来说是种考验。 它可以让我比以往任何时候都更加深刻地自省，扬长避短，精益求精，不在无望的赛道上浪费时间。 4.更为可贵的是，AI可以让我反思当下自我的生活。未经思考的人生不值得过。那现在我们都有可能自觉不自觉地反思自我，从而改善整个世界的概率分布。尽管跟别人比起来，我的人生不那么辉煌，不那么耀眼，但在AI的加持下，我有可能达到自己天赋的最高峰。只要我全力以赴，奋力拼搏，这依然是一种值得过的人生。 5.我很厉害，拥有很多我们都知道——可是我们\*不知道\*我们知道 —— 的常识。不止于此，我们要把这些常识告诉我们的AI伙伴，去创造属于我自己的，哪怕只有15分钟的巅峰时刻。

Gigi11小时前

好神奇！今天的日课让我想到一个关于记忆移植的实验， 2013年时候，南加州的西奥多伯格教授做过这样一个实验，先放一个芯片在猴子大脑里，然后训练他做特定的动作，之后把芯片提取出来，再植入另一个猴子的脑中，新猴子在完全没接受过训练的情况下，可以做出旧猴子被训练的动作！ 后来这个教授也给人类做了类似实验，也都很成功。但是这项技术的瓶颈在于，每次只能储存一小段记忆。 如果记忆移植技术突破，那么我们人类的常识就可以完全移植给AI，AI是否就是一个新的物种了呢？或者说，人类进化成了每一个人都可以拥有全人类的常识？

强Sean5小时前

1、context（场景）比content（内容）重要。我们有时候说一个人很二、没脑子，就会说这个人像个机器那样。他的智力是正常的，但他对语境、场景缺乏感受力，它有content，但是他没有context。 2、4岁儿童 VS 机器人:我们看一个4岁的儿童，他不仅能够听话、说话，还能够察言观色、眼观六路、耳听八方，能够在不同的场景里切换自己的角色，从而让自己的生存空间、利益最大化，在这一点上机器人是远远做不到的。这是人类和机器很大的不同，人类是具有社会性的，而机器没有社会性；人类的生存都是场景化的，而今天的机器人、今天的智能设备是很难具备社会性的身份，很难具备场景化沟通的能力，机器的情商、社交商、领导力商都非常低。

陈C10小时前

日课讲过很多次AI的局限，学了这些，除了知道AI不能做什么外，反过来倒是一次比一次惊叹，我们人类能做的事情太多了，我们的智能是何等奇妙，以至于我们自己都不清楚它到底有多厉害。也许比起研究如何改进AI，我们更应该多在认知科学和神经科学上下点功夫，好好琢磨明白我们自己才行。 不过事情也并非绝对。人类从直接在自然中取材，到拙劣地模仿自然，再到从自然里发觉规律，再到运用规律制作和改进工具，车、船、飞行器等等，无不经历过这样一个过程。而对这个星球上最复杂的东西，人脑的模仿，自帮助我们创造出了高效率的AI。但更奇妙的还是“反向”认知，比如通过对人造的车船的研究，进一步理解流体运动，以及通过研究AI，反过来认识我们的大脑。 相信像这样，对AI和人脑的研究“齐头并进”、相辅相成，会给我们带来更多的惊喜。进一步讲，包括基因在内的更多的复杂事物，也许也能借由类似的思路，从不同角度展开，取得更深入的进展。

佛祖门徒6小时前

常识、能动性、感受性等这些概念在平时没有主动去留意过，却如同呼吸一样自然。 最近在学习隔壁陈海贤老师的《家庭关系课》，于是想到如果处在人际关系中的AI，是否能够理解人类语言、情感或行为背后的真正含义。对于一句埋怨、一次挑剔、一些互动，人类尚且需要仔细体验和长期经验才能有所体味并找到适当的回应方式，AI恐怕在相当长的时间内都只能做一个让人哭笑不得的“直男”吧？

悍那Hana3小时前

智慧是一种“明智的推理”，是通过理性，应对挑战，做出判断。 学校里的应用题，明确的已知条件总有限； 现实中的判断项，潜在的前提常识却无限。 但，什么是大数据、什么不是大数据，并非铁板一块，而是一个不断变化、不断发展、不同行业不同标准的概念。 这些变化，是向显性不断推移的常识库，是不断累积的推理资源；不论智慧程度与否，它们已经改变了工作的方式，也会改变整个世界。

黄礼贤4小时前

办案常识 拥有常识是人类优于人工智能之处。对于办案来说，法律的基本规定和逻辑性的法则，就是一种办案常识。只要具备一定的法律基础知识和受过基本的教育，都是应该知道的。 例如，在同一个时间内，办案人员不可能同时讯问两个以上的嫌疑人；与嫌疑人谈话应该用讯问笔录，证人谈话用询问笔录；复制文书应该复印盖章并注明出处。 在实际办案中，有些办案人员还是会犯常识性的错误。在检查中，出现同一办案人员在一个时间内讯问两个以上对象，而且经常用错讯问与询问的笔录头。 为何出现？我觉得跟办案人员的程序意识不强有非常大的关系。从逻辑上讲，一个办案人员不可能分身，但因为不注重程序的意识，没有按照规定现场签名，于是，在制作多份笔录以后，在事后补签名的情况下，就可能出现这种逻辑性的错误。 如何避免？可以从两个方面入手去改进。一方面树立办案人员的程序意识，将程序与实体并重，严格按照相关规定行事；另一方面，增强监督与制约，特别加强对程序的审核工作，让办案人员不敢马虎应对。 具备常识是快速推进案件的优势，但如果不按常识行事，就可能面临严重的办案错误。利弊之间，很容易快速转换，学会利用常识为办案服务，是办案人员应该坚持之道。

Bruce昨天

你有你的计划，世界另有计划 Ⅳ Day671 No1 前不久终于集中时间看完的《巨人的工具》，给我启发最大的，并不是各种高手的建议，当然确实不错。最让我受启发的还是人不管什么时候都不能看轻自己，这和人经常是过度乐观结合起来更有趣。这就不免让人想到了理性乐观。 当我们看到人工智能扑面而来，可能会被它所吓到。当看完《为什么》又会觉得不值一提。其实现实情况更加复杂，不是一分为二，更是需要具体情况具体分析。不妨像曹操在官渡之战时谋士的分析，我们既要看到自身的优势，又要看到不足，更为重要的是客观评价之后的那份自信。不能被击垮，更应该迎难而上，只不过要多一点智慧，多动动脑子。

努努昨天

谢谢万老师今天提到的我们人类相较于AI的特长，这是一个很有意思的话题。 AI被认识到的强大是从阿法狗战胜李世石开始的，随后我们人类意识到AI的强大，但是毫无疑问这是一个错觉。目前的AI，并没有强大到我们想像中的地步，它能做到很多人类做不到的，也有很多我们人类觉得很简单，它却无能为力的。如果说之前我们低估了AI，那么现在很有可能我们高估了AI。 搜索了一下AI目前还很“稚嫩”的能力。 一是常识。也就是普通知识，一个生活在社会中心智健全的成年人所应具备的基本知识，包括生存技能、基本劳作技能、基础自然科学和人文社会科学。比如两岁孩童都能理解的直观物理过程，比如高处的物体会下落，人类不需要学习物理学也能预测，但是AI不能。这些知识是无需特别学习的。 二是抽象能力。在思维活动中，通过对事物整体性的科学分析，把自己认为是事物的本质方面提取出来，舍弃不主要非本质的东西，从而形成概念的能力。比如孩子看到第一辆汽车以后，自动会把汽车抽象成一个盒子下面四个轮子，这个抽象模型会让孩子迅速识别出不一样的另一辆车。而AI没有这个能力。主要是我们不知道如何教会AI该舍弃哪些因素，保留哪些因素。 三是自我意识。威尔·史密斯的电影《I，Robot》讲的就是一个机器人拥有自我意识以后的故事。目前的AI还不具备自我意识，动物中具备自我意识的，我们人类会觉得这是聪明的动物。比如猩猩、海豚、乌鸦、大象等等，主要是看动物是否能从镜子里观察自己来区别。 万老师举到的例子中，救小女孩还是救机器人，之前和菜头回答过熊逸老师到底是救猫还是救人。我觉得在人和机器人之间，我们之所以会救人，原因还是机器人还只能算物，都不能算生命。

王福斌4小时前

AI总是讲面对的问题先简化成某种规则，这也是人的某种外在的能力，可是很多事情还没办法简化成规则，这是千百年的的积淀，是自然选择的结果，AI不知道，人不觉得知道。 前几年看到一个关于翻译的文章，谈到两种语言不能精准翻译举到例子，三长两短，用棍子打不出个屁来这些中国人心领神会的说法，也许在另外的语言环境里面有，却总是失去了味道，那个味道是翻译越不过去的沟。 单位里上ERP系统，我主导，从逻辑到构架再到具体的模块，每一个细节都经过仔细的推演和论证，到系统上线以后领导希望我告诉他一些关于系统的东西，可是除了那些最简单的输出我却不知道从哪里做起，每一个模块对我来说都是习以为常，对领导却是别有洞天，领导是那个AI，而实际AI面临的问题却更复杂的多。

donwe昨天

1、AI依靠人脑开发，需要大量的数据投喂，数据积累；人脑归根结底由父母的基因绝对主导，是由DNA决定，而DNA的双螺旋结构隐藏了无数的信息，这些信息既有先天，又有后天训练拓展。 2、机器学习的最大优势就是海量数据，比如下棋而言，机器可以精确的计算出数以百万的走法，而人能计算的数量极其有限，只能以类似“哲学”的思想表达棋技。但是成也数据，败也数据，也许过于依赖数据量化，使得机器对于感性认识方面毫无头绪，感性无法量化，而这又是人必不可少的交流学习方式。 3、“有一种胜利叫撤退，有一种失败叫占领”这是一句台词，AI是听不懂的，但是看电视剧的人都能体会其中的含义所在。情商是AI学不会的，变量太多：环境，文化，习惯等各种因素都需要考量，而且其中也没有排他性的唯一答案。 4、除去感性的语言交流，还有心照不宣，心有灵犀，此时无声胜有声的交流方式。这些都让生而为人的我们确实更高级一点![[./_resources/»_日用而不知的难题.resources/1f606.png]]

菜菜6小时前

所以是不是给哲学又留出了空间？ 尤其是中国哲学。 万sir您放心，我是被熊逸书院启蒙，不会跪着读经典的人。 我们每秒接收到的信息，其中意识能识别比例太低。而人脑是自然演化和社会共同创造的产物。 那么，我们的情绪、感觉和爱等等，才是大脑这台机器运算出的结果。 而中国传统哲学对人之间信息的处理，佛学是个体对接收信息的处理，分析的结果，更像经典物理学基于宏观观察找到的结论。 哲学加生物、基因等等科学手段，才能进入进一步的计算。

郑冲昨天

万老师这是放了一个观点出来，并且证明了它，然后没带任何拓展，看完我就想问，所以呢？ ……没想出来可以有什么高级共鸣，因为我发现精英日课还有9期，第四年的内容就结束了。 在这样的情绪下，想感慨，身为精英日课的读者，你都不知道你有多厉害。 同学们有仔细体会过精英日课是个什么样的存在吗？ 我反正现在看各种内容都似曾相识，又能发现更多乐趣。 我学会了用正反两种态度看问题，还知道尊重最优解和主流共识。 我知道了真正的科学，会向人文回归。 我总结出了最强的读书和做笔记的方法，虽然还没有做到。 我明白了自己的读书能力，可能永远比不上某人，但他可以激励我继续读下去。 ………… 连我的座右铭，几乎完全是从四年日课中总结出来的， 那是什么座右铭呢？ 用它来做今天的留言总结再合适不过了—— 真相有意思，思想永不眠 我算不上铁粉，没有多少傲人的数据，专栏也是有选择的看和留言，也有不认同万老师观点的时候，我只是一个普通读者，我跟了四年。 但是， 自豪吧，老师同学们，我们真的很强。

林曦3小时前

万老师好。 本节课的主题，不妨还可以较为直观地理解为： 相比起AI，人类为什么可以掌握如此多的常识？ 个人浅薄地认为，可能有以下原因： 其一，人类非常擅长利用\*故事\*。 故事可以抽象出概念和道理，而抽象的概念和道理，又能通过故事的包装加以阐述和传播。故事，还可以通过前因后果，训练出最初的逻辑思维，建立各种道德观念和感性认识。 其二，人类非常擅长“脑补”。 正如前面的课程内容所述，遇到还不能完全理解的现象和知识，人们通过“脑补”，先将其合理化，以便大脑腾出空间，随时接收和处理新的外界信息。 更何况，那些曾经的合理化，也不是一成不变的。随着年龄和阅历的增长，进行着“贝叶斯”式的修正。 其三，人类的学习，往往是主动和被动并存。 目前的AI，主要通过投喂大量的数据进行学习。而人类，不管是青少年还是成年人，不仅能学习别人提供的信息，还能主动搜寻外界信息，甚至能学习自己身上产生的信息。 其四，反馈很重要。 不管是小时候咿呀学语，还是长大后的工作和生活，接收、识别、创造和利用各种反馈，是人类在学习过程中的一大优势。

朱颖4小时前

去年和一个研究自动驾驶的朋友聊，她说研究得越多，对自动驾驶就越没有没有信心。因为我们不能提前预估所有的情况，很多时候只有发生严重事故了才知道。这里面应该就是老师说的我们“不知道”自己知道。就是很多常识。是不是说其实我们担心被人工智能取代，是没有必要的？人之为人不光是感性的，更是很多理性的，一种自带的对事物认知的基础能力。

良11小时前

记得李宏毅老师的机器学习课里有一节，他尝试用机器训练宝可梦和数码宝贝两种卡通动物的区别，结果准确率高到离谱。于是他检查了一下发现，原来两种图片透明背景色不同，而AI只是在识别背景的颜色。另一个例子是有人训练肿瘤的图片集，训练的结果很理想，结果一实测发现啥用都没有。后来发现原来医生们总是在确诊的肿瘤旁放一把尺子再拍照，AI只是记住了尺子，并不认识肿瘤。。

Aming昨天

研究了AI，才知道身为人类有多么的厉害。 其实不仅仅人。动物识别物体的能力也远胜于AI的。起码宠物不会因为主人上面贴了张图片就视而不见。更何况它们还能借助于嗅觉，味觉和触觉多维度识别。 这些复杂功能实现只伴随极低的能耗，不得不让人感慨自然的神奇。

白露塞纳昨天

我是谁呢？ 空泛地谈没意义，你需要从关系的视角去分析与对比。 同人对比，才知道你长处、开放性、努力、漂亮程度等。 同机械对比，才发现，人不擅长重复，不喜欢当一块砖。 同AI对比，才知道人本身掌握了大量隐性知识，这些日用而不知。

张洋7小时前

“爱使我们有别于人工智能”，其实不光是“爱”能够区别双方，许多方面两者都存在不同，人工智能有它的优势，我们也有自己的天赋，在一些方面，它们确实可以胜过我们，但在有些方面，我们也远领先于它们，尤其我们可以从胜利中感受到喜悦，也可以从失败中吸取教训，我们有对成功的渴望，也有对挫折中的反思。在有的人看来，面对人工智能的就如同大敌当前，也有的人会讲，拥抱人工智能就是抓住未来，而在我看来，人类与人工智能更像是一个大人领着一个孩子，当然这个孩子有可能在将来成长为“巨人”，一些顾虑、担忧是正常的反应，但也正因为如此，我们就更应该关注它，教育它，善待它，直到它变成“他”。 虽然在未来，一些常规（重复性）工作可能会被人工智能取代，但创造性的工作很可能仍然只能由人类来完成。记得以前有幅漫画，里面画的是未来人的样子，大脑袋小身子，这是一种想象（可能也是种讽刺），现在想起来，好像真的是这么回事，人工智能不仅可以成为我们身体的延伸，还可以成为我们大脑的一部分，人类可以提出设法，然后就交给人工智能去探索、去钻研，然后再将反馈交在人手里，是接着开始一番循环，还是就此打住。 夫尺有所短，寸有所长，物有所不足。智有所不明，数有所不逮，神有所不通。

芳昨天

很想问万老师一个问题，如果AI有这么多的“命门”，那么我们对AI还可以有多少的信任度呢？尤其是AI在医疗上的使用，那可是关乎人命啊！比如手术机器人，如果有偶尔的判断失误，那失误的就不仅仅是图片了。现实中有一些化验仪器的问题导致结果会出现很大的偏差，直接影响医生对病情的判断。

作者回复：

IBM沃森项目现在看基本上没有达到预期，好像正在谋求出售。医疗诊断还是得靠人，这是目前的结论。

该隐昨天

万老师您好，所以像泰格马克在《生命3.0》开篇设想的“普罗米修斯”永远无法实现，或者起码是离我们很远？

作者回复：

现在看非常远，但是你不知道接下来会发生什么……

卷毛3小时前

中原文明非常不理解草原文明“哥哥去世，弟弟娶了嫂子”的情况，认为这是“非礼”。可是中原文明却认为“姐姐去世，妹妹嫁给姐夫”非常容易理解。原因就是中原文明和草原文明各自有着不同的文化背景，以及不同的文化演化路径，作为中原文明的我们日用而不知。

牧风4小时前

我们追忆似水年华，但是有谁能够记得3岁以前到在受精卵之间这段时间发生了什么，好像什么都没印象了，那个’我’去哪里了？ 那时候，一定知道哭笑闹，慢慢学会行走说话… 即使现在的’我’不记得，也天然会这些，可能是因为基因遗传天然让身体会这些，即使’我’感受不到基因，或者感觉到什么本身就是’基因表达’， 如果人是AI 可以一眼知道美女帅哥，可能因为有好看算法， 可以害怕本能避险，可能有’恐惧基因组遗传’表达残留… 如果人也是模块化AI 如果AI进化到强人工智能，TA可能会研究检查自己的特定表达的基因

戚志光4小时前

比利时鲁汶大学的科研人员发明的那张A4纸，让我想起了《攻壳机动队》里的微笑男人，假如我穿上了这样一件T恤衫，对于人脸识别的AI系统来说，我就相当于“隐身”了。 而且这玩意儿让人细思恐极，如果未来的安全措施大量依赖于摄像头的人脸识别，那犯罪分子靠这种漏洞就有可能骗过安全系统；像特斯拉的自动驾驶靠视觉识别行驶，如果一个人因为类似的原因恰好无法被识别出来，就有可能出车祸。 现在的人工智能虽然给人感觉很强大，但是还有数不清“命门”啊。

然简AI9小时前

猜测 1人脑中包含固有知识，甚至基因和环境操控神经网络来架构实现前者。 2固有知识：万事万物的内在骨架，共性的,和常用的，比如人从祖先开始经常接触人脸，人际关系，其他关系，家禽动物样子，道路，抽象的数字和关系～～ 人脑会根据注意力机制(ai也在用)，也是优先级，做概率性猜测识别。 意识，本质也许基于注意力，即识别客体为什么东西的优先级。 固有知识，其实进行分类归类，并没有那么多。万事万物其实内在包含的东西，有着惊人的共性，差异很小…这也是人脑可以快速组织识别的关键。 3这些\*固有知识\*会和人脑即时感知处理的当前\*信息\*加以 类似于向量在几何空间的组合…使得人可以立即感知。 现在流行的embedding嵌入技术就是万事万物向量化，且即刻随意组合计算。 在梦中,这时候人脑对感知到镜像进行各种排列组合。 4人脑感知到的万事万物,应该都分为三层：功能层，逻辑层，物理构成层。 尤其是人脑直接可以对事物属于什么功能的识别。 这个非常重要。ai没有对事物这三层的同时感知。 人脑也许也是这样。 5人脑并不是如ai那样只能单向，而是双向识别客体。 做到对客体从微观到宏观，从宏观到微观；从功能角色到逻辑到物理层实体，和反向～… 两个方向的同时进行。 且人脑建立起三个层次的对象间映射，双向映射。 6ai肯定无法实现人脑中的物理层，但是大脑中的逻辑层肯定可以实现！在于逻辑层就是纯数学(关系结构，对象 )，用软件实现数学,轻而易举。 人工智能肯定会出现极大的新突破,只是现在的排列组合依然不够。 人工智能可以是各种软件模块混杂在一起，不仅仅包含统计模型， 神经网络在其中，也包含一些基本算法，基本的行为操作(比如一般的软件算法，什么查找排序，动态规划的都用上 )在其中，混合。 且一个ai智能体，完全可以多个不同的模型，比如NLP,,cv等，同时工作对客体识别处理，大家得出答案，然后合成统一表决。 现在的人工智能，并不是没有前途，也不是没有方向。 只是排列组合，天马行空各种混搭的努力还不够～～继续坚持…… 甚至人的意识和脑内镜像感知，情感能力，也不见得是没法功课的 人工智能和生命，是互相促进的

民非9小时前

人的认知能力不追求细节上的准确，而是探寻整体的把握，是不断对认知模型做简化，总在试图把零散的知识抽象概括成更为普遍的知识，一般化过程中，可以牺牲一些精确性，只要意外特例构成的损失不太大。总结出来的一般性认知，更容易拓展到新的环境和未见过的场景和样例。为了验证拓展模型的正确性，人类认知有假设检验的方法论，可以主动通过实验来排除不正确的模型。这个学习能力是内禀的，天生的。而机器学习，就是从细节入手，关照准确率的提升，靠数据量，两个学习的思路有本质的不同。

郭成9小时前

万老师，今天讲的人比AI优越的分析能力让我思考是否采用神经算法解决复杂问题的研究思路本身在提升效率的主要目标下抛弃了很多细节，因此最终会将训练数据的特征错误当成追求的目标，从这个角度来看，破解人工智能其实破解的就是模式化偏见。从这个角度出发，未来就会出现官方的人工智能和专门破解官方智能的智能，这种发展可以削弱科技公司的人工智能对人类的掌控，因为攻守成本的不平衡，这或许是为人类提供智能时代存在意义的关键。

山居秋暝11小时前

感谢万老师的分享。 您今天的课程让我想起那个“技术成熟度曲线图”包括科技诞生的催动期—过高期望的峰值—泡沫化的谷底期—稳步爬升的光明期—实质生产的高峰期等阶段。学生以为AI发展正处在过高期望的峰值与泡沫化的之间阶段，但这又是必经历的过程，发展就是要“乱来”，激发产业创新能力，是骡子是马先拉出去溜溜，当年百团大战留下的只有美团，共享经济竞争产品最后也所剩寥寥无几。 人是活的，是各种情感纵横交错的集合，想起姜文《有话好好说》里的那句：“你理解？我自己都不理解。你理解？”我想，目前AI优势是数字化时代的工具，各种算法的优化方案，是人的参谋助手。过多鼓吹AI万能作为科技公司的宣传买点，脱离实际，会导致研发精力分散，陷入固定式思维陷阱，停滞不前，就像王煜全老师讲的：不讲产业化时点的黑科技都是耍流氓。 AI再强，还能强过我们的情感，还能学到我们的精湛，就比如窦唯当年唱的那首《高级动物》（第一次复制网上内容，见谅），AI，它，它，它行吗？ …… 矛盾 虚伪 贪婪 欺骗 幻想 疑惑 简单 善变 好强 无奈 孤独 脆弱 忍让 气愤 复杂 讨厌 嫉妒 阴险 争夺 埋怨 自私 无聊 变态 冒险 好色 善良 博爱 诡辩 能说 空虚 真诚 金钱 噢~~我的天 高级动物 地狱 天堂 皆在人间 伟大 渺小 中庸 可怜 欢乐 痛苦 战争 平安 辉煌 暗淡 得意 伤感 怀恨 报复 专横 责难 幸福在哪里 …… 谢谢万老师，祝春祺。

犀山客昨天

说一个语言方面的感受： AI越来越让人惊叹，因此也越来越多的人认为有了AI翻译，学习英语或母语外的另一门语言已经没有太大必要了。 语言作为工具的基本功能是沟通，但语言背后是人类文化和活生生人的情感。就像如今在广东不懂粤语已不影响沟通，但一个懂粤语的人和一个不懂粤语的人聊天与两个都懂粤语的人聊起天来是很不一样的，前者会稍显干瘪和少点乐趣，这背后是地域文化和情感的差异。 所以，想要活得丰富、主动一点，学好外语特别是全世界通用性最强的英语还是有必要的。 重要的是，学好了英语，将来才能更好和更主动的跟机器、AI沟通。

芳昨天

这节课听的实在是应景，我今天心情特别差，因为工作单位现金流紧张，也许要撑不下去了，对自己的前途很迷茫。正是睡不着的时候，听了这节课，“你遇到各种情况都知道该怎么办，可是如果没遇到那些情况，你说不清你知道多少个“怎么办”。“哈哈，原来是事情还没发生，所以我觉得迷茫，等企业真的撑不下去了的时候，我就知道该怎么办了。好吧，我相信我可以的。 这几年跟着得到学习，最大的感触就是这样，每次遇事不决或心情沮丧时，打开得到的课程，总会得到一种能量，一种让我豁然开朗的能量，感谢万老师，为我赋能。

作者回复：

深感荣幸，谢谢您！

小小罗帅呆了4小时前

Ai![[./_resources/»_日用而不知的难题.resources/1f916.png]] : 你们人类不讲武德，不按套路出牌。 人类![[./_resources/»_日用而不知的难题.resources/1f468-200d-1f4bb.png]]![[./_resources/»_日用而不知的难题.resources/1f469-200d-1f4bb.png]]：那我们重新定义一下武德
